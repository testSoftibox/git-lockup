#+STARTUP: hidestars

git-lockup: Ensure the validity of your git checkouts

Also consider https://www.agwa.name/projects/git-crypt/ or
https://github.com/blake2-ppc/git-remote-gcrypt for confidentiality.

* usage
  - this package has a bunch of source code, but only creates a single .py
    output file, "git-assure"
  - committers should run "git assure setup-push" from inside a .git tree
    - it will compile python-ed25519 and install a hook script that runs on
      'git push'
    - then it will ask for a key name (usually the name of the project), and
      create the private key in ~/.git-assure/KEYNAME.signingkey
    - it will store key name (but not the key itself) in an unused .git
      directory. It will also record the public verifying key there.
    - it will also ask for a place to write the user scripts to. This should
      be some sort of "misc/" directory in your source tree. It will write
      three files there: the original "assure" script, the public verifying
      key, and a README.git-assure with install instructions for users. These
      three files should be commited and published in your git repo. You may
      also want to add notes to your top-level developer-oriented README file
      pointing at these instructions.
  - users (i.e. your developers who do 'git clone' and 'git pull', but not
    necessarily 'git push'), should see these instructions, which will tell
    them to run "assure setup-pull"
    - when they run that, it will compile python-ed25119 and install a hook
      script that runs on 'git fetch' and 'git pull'
    - the public verifying key will be copied out of the source tree into an
      unised .git directory. This prevents it from being modified by git
      operations like 'pull' or 'checkout'.
* data storage
** ideally put the signatures in the repo with 'git notes', attached to each
   revision
*** when a committer starts to use this, the new refs/notes/commits branch
    needs to be pushed manually
*** a 'git clone' after that branch is present will pick up the notes
*** but if the 'git clone' was done before the branch appeared, a subsequent
    'git pull' won't
*** so "assure setup-pull" should get them too
*** 'git clone' from a github repo with refs/notes/commits doesn't get them
    - 'git ls-remote' shows them
    - 'git fetch origin refs/notes/commits:refs/notes/commits' works
    - but it doesn't seem sticky: normal 'git fetch' doesn't update it
      - ah, probably since the default in .git/config is fetch =
        +refs/heads/*:refs/remotes/origin/*
      - may need to add a +refs/notes/commits:refs/notes/commits during setup
    - I think the same is true for push
*** TODO hm, needs more work. Looks appropriate, but moving them around
    requires some care during setup
** if that doesn't work, put them in a separate github "Gist", and store the
   repo URL of it next to the pubkey
* signature format
** one signature per line
** message body is like "master=633641174a7bf18e49bdef581d31fdfcc603d39e"
** sample: signing.key=unhexlify("7369676e302def04727e9a23d8fa1a66787300df0c6781edde5adbb17c68488c33ee1919447a")
** lines are "assure: BODY SIG KEY", like:
   - assure: master=633641174a7bf18e49bdef581d31fdfcc603d39e sig0-7mul5nbgdghmu4mywgtpjsj3skrxyxcwub7apnunlzcgzyw2awvdcaycfuymvxqvuzijd5hxfxpgeztmjuhvisapcq3aj3utfbk56dq verf0-2gy3ublnkjoeyorb234vkqqajlm5mgej3koepk4hr6aqkmm2wuwq
** 'git notes' has provisions to cleanly merge+dedup line-based notes
* development
** this tree will contain a bunch of source code, and a build step will
   create the one "assure" output file
*** that will be a python program with commands like "install-push" and
    "install-pull"
*** it will contain a ascii-encoded copy of python-ed25119
    - without the 2.5MB known-answer-tests, it's a 65kB .zip, 86kB base64
*** it'll compile that in a tempdir, and install into a quiet .git/ dir
    - .git/ASSURE-TOOLS maybe?
    - the hook script will add it to sys.path before 'import ed25519'
** DEV PLAN:
*** study hooks, identify the right ones
**** "post-commit" for outbound: no parms, cannot affect outcome of git
     commit
**** we really want a "pre-merge", but there isn't one
     - pre-receive only says it runs on the server side
**** "post-merge" (takes a single "is a squash merge" flag)
     - runs after merge, and cannot affect the outcome
     - but it could reset the branch back to an earlier (good) version
     - it also doesn't help us check parentage
       - we need to check that the new rev is a descendant of the old rev
       - which means we must know what the old rev was
**** post-commit isn't run after a pull or merge, only 'git checkout'
**** hm, we could use a proxy, or a magic remote protocol
**** oh, I think post-merge has enough information:
***** we know what HEAD we're on afterwards (say "master")
***** use the reflog to find out what master was beforehand (can't tolerate
      octopus merges)
***** examine master's current revision to identify all its parents
***** one of the parents is master@{1}, so ignore that
***** use git-config to find out what master's upstream branch is
***** compare the other parent against the current value of the upstream
      branch, this identifies a normal merge
***** now do the signature check against that upstream branch value
***** and do the parentage check against our remembered upstream value
***** remember that upstream value for the next time
**** hey, 'git reflog refs/remotes/origin/master'
***** so first, figure out what the upstream branch is
***** then find out what the current value is. If that is a parent of the
      current post-merged HEAD, then this was an upstream pull, so we need
      to check stuff
***** we've remembered some previous value of the upstream as valid. Check
      that the new value of upstream is value and that it is a descendant of
      the remembered value, then update our memory.
**** huh, that's hard stuf
***** so one tool to start with would be just a checker: look at all remote
      branches, check each one (current value is signed, and is a descendant
      of a previously accepted value).
****** we'd prefer to run this during during fetch, just before setting
       refs/heads/remotes/REMOTE/BRANCH to the new value, where we'd like to
       abort the assignment on failure.
****** we could also run it after fetch (but before merge), in which case
       we'd roll back the REMOTE/BRANCH ref to the previously-accepted value
****** we can run this during the existing post-merge hook, and learn about
       historical problems, but if there were any problems, mitigation is
       tricky
****** to help with that, the routine should return (last-accepted,
       current-bad) for each problem branch
***** second routine is to figure out whether the recent merge was affected
****** since the post-merge hook runs immediately after each merge, we can
       use the current branch's reflog to find out its previous value, and
       at the current revision's parents to figure out it's history
****** we might also take advantage of knowing this branch's upstream name
****** we ignore the parent that equals reflog[-1]
****** then there's a set of merge scenarios:
******* lots of holes, especially if the user does a bunch of fetches (but
        not merges, so we don't get control), then merges in some
        intermediate value
******* toughest case is probably:
******** upstream pushes signed values for both branch "master" and branch
         "evil"
******** attacker tries to trick user into getting "evil" when merging from
         master
******** by the time post-merge happens, we've lost information about what
         they were trying to merge from. If they did 'git merge
         origin/evil', then it's fine. If they did 'git merge origin/master'
         and got the evil rev, then that's an attack.
******** parentage tells us which revision was being merged, but not the
         semantics (which branch name was being used)
******** might glean it from the merge comments? ick.
**** probably safer to simulate a fetch-hook by using a separate remote
***** upon install, replace the remote with a special handler, and move the
      original to e.g. "origin-raw"
***** the replacement URL would be like "gitlock::origin-raw"
***** then write a remote-helper for scheme "gitlock" that starts with a
      normal git-fetch of the raw remote, then checks the branch values
      before copying them into the processed one.
***** hm, pushes would need handling too, should just pass-through, but
      update the branch values.
      - git-fetch documents a [url NEWBASE]insteadOf=OLDBASE and
        pushInsteadOf=OLDBASE which can rewrite urls differently for pushes
        and pulls
***** would be nice if git exposed its handler for git/ssh/rsync protocols
      - transport.c line 917
        - get_refs_via_connect, fetch_refs_via_pack, git_transport_push,
          connect_git, disconnect_git
      - connect.c line 447 git_connect()
****** 'git push' uses 'git-send-pack [[user@]host:]repopath' on the near
       side, and runs git-receive-pack on the far side
****** 'git fetch' uses 'git-upload-pack' on the far side and runs
       'git-fetch-pack [host:]repopath' on the near side
**** easier special-remote (still a hassle):
***** git config set remote.NAME.vcs ASSURE
***** then exec(git-remote-ASSURE, REMOTENAME, URL)
***** our git-remote-ASSURE starts by doing 'git fetch REMOTENAME-raw', let
      it run to completion
***** then examine all branches in REMOTENAME-raw, check signatures and
      parentage, throw exception (exit with rc=1) upon problems, then the
      real 'git fetch' will report a remote error. Bonus points for getting
      the error message to stderr.
***** then we "just" need to implement the real remote operations
***** easiest is to advertise "connect" capability, then parse URL and
      simulate git's builtin connection handlers
****** if URL happens to be http/https, just exec git-remote-http
******* do this before interpreting any part of the protocol, let
        git-remote-http handle everything
******* 'git-remote-http' uses http-fetch.c and http-push.c
****** else, need to parse URL (ssh/git/file), advertise "connect", wait for
       the connect command to be issued with a 'service' argument, then:
******* if ssh, exec[ssh host git-receive-pack|git-upload-pack (args..?)]
******** maybe check for some .git/config options (using something other than
         git-receive-pack, etc)
******* if git:, exec netcat and maybe send a command name
******** my flappserver handler (git-remote-pb) does this
******* if URL is file:, exec[git-(receive|upload)-pack]
**** ok, my git-remote-passthrough is coming together
***** cases to test:
****** DONE HELPER::rest_of_url
****** rsync:
****** DONE /path/to/local
****** DONE file:///path/to/local
****** TODO git://host/path
       - doesn't work yet, I think the git protocol has an extra message
****** git://host:port/path
****** DONE ssh://host/path
****** DONE ssh://host/~/path
****** DONE ssh://user@host:port/path
****** DONE other ssh synonyms: git+ssh, ssh+git
****** DONE helper://rest
****** DONE host:path
        - luther:/tmp/t.git
****** actual URL values:
	url = /Users/warner/stuff/vc/git/git-assure/t/one
	#url = file:///Users/warner/stuff/vc/git/git-assure/t/one
	#url = luther:/tmp/t.git
        #url = ssh://luther/tmp/t.git
        #url = ssh://luther:22/tmp/t.git
        #url = ssh://warner@luther:22/tmp/t.git
        #url = ssh://luther/~/t.git
        #url = ssh://luther/~warner/t.git
        #url = ssh+git://luther/tmp/t.git
        #url = git+ssh://luther/tmp/t.git
        ##url = git://luther:9418/tmp/t.git
        #url = https://github.com/warner/python-ed25519.git
        #url = passthrough::https://github.com/warner/python-ed25519.git
        vcs = passthrough
**** nov-2012, does git make this any easier now?
***** git-remote-fd lets you set up your remote connection first, attach it
      to some spare fds, then run 'git fetch fd::12,13' to bypass (manually
      control) the connection setup phase. It then speaks the git protocol
      over those fds (or a single bidirectional one).
***** git-remote-ext is similar, but takes a command to spawn that will
      create the remote connection (it then speaks the git protocol over
      stdin/stdout of the child process).
***** git-remote-helpers is a python library that provides local-repo
      commands (list-references, get object, etc) to build remotes that
      manipulate local repos more easily
***** no post-fetch hook yet.
***** to simulate a post-fetch hook:
****** do real fetch to some parallel/related remote
****** run post-fetch hook (which might raise an error)
****** copy refs from the parallel remote to the real one
***** hm. maybe 3 remotes: A,B,C. "A" is the real upstream, so when the merge
      finally happens, it will pull from A. The URL for A points to our
      special helper, somehow. When the helper gets control, it first resets
      all of B's refs to whatever is in C. Then it does a normal 'git fetch
      B', which grabs everything without checking, then runs the post-fetch
      hook. If the hook passes, it copies the B refs to C, then copies the B
      refs to A, then exits with success.
***** that allows the upstream to be reset without persistently breaking the
      local copy (C will always be good). Oh, A is enough for that.
***** two remotes: real, temp. 'real.url' points at the special helper,
      'temp.url' points at the real remote repo (during setup, just copy
      real.url into temp.url [for push only]). The magic remote-type in
      real.url gives control to the helper. The helper overwrites temp's refs
      with those from 'real', then does 'git fetch temp', then runs the
      post-fetch hook, then maybe copies the new refs from temp back to real.
      Maybe even create 'temp' each time, then delete it afterwards. Problem:
      the top-level git-fetch has to be negated somehow, turned into a NOP.
***** oh, better: special helper does: copy real refs to temp, 'git fetch
      temp', run post-fetch hook, then uses the "connect" capability and
      execs git-upload-pack pointing at the local repo. Modify the
      read.refspec to pull from refs/remotes/temp/* instead of refs/heads/* .
      Then the top-level 'git fetch' will do the temp-to-real ref copy, and
      we don't have to figure out how to NOP it.
****** all fetches will fetch all branches, unless there's a way to glean the
       'git fetch' arguments in the remote-helper and pass them into the 'git
       fetch temp' command. Most likely outcome is limitations on the
       original 'git fetch' command will be ignored.
*** outbound
**** DONE script to create signature to stdout, using system-installed ed25519
**** DONE then add it to a 'git notes'
**** then figure out what .git/config is necessary to push notes
*** inbound
**** DONE script to extract note
**** script to check signature, check parentage
**** attach to hook script
**** figure out .git/config needed to pull notes
     - maybe pull them from the hook script, slightly slower
*** then packaging:
**** change scripts to use PYTHONPATH=.git/private
**** figure out receiver-side installer
**** figure out sender-side installer
**** figure out installer-builder
* replay protection
** if enabled, just assert that the previous value of the branch is an
   ancestor of the new proposed version. Git takes care of the rest.
* studying fetch.c
** do_fetch()
*** get_ref_map()
*** fetch_refs()
**** transport_fetch_refs
**** store_updated_refs() writes the file
** ok, I think the problem is that the [branch "master"].remote and .merge
   pair don't point at the same thing that [remote "origin"].fetch does
*** changing .merge to say "refs/remotes/origin-temp/master" works
*** fetch.c L177 is the relevant section
*** hm, add_merge_config() is probably more relevant
** hm, $GIT_TRANSPORT_HELPER_DEBUG=1 enables remote-helper debug messages (in
   transport-helper.c)
** transport dispatch is in transport.c:transport_get (line 912)
*** explicit helper (config .vcs or url=HELPER::stuff) is handled first
*** then rsync: is dispatched to native code (get_refs_via_rsync, etc)
*** then local/file is dispatched natively (get_refs_from_bundle/etc)
*** then builtin smart transports are checked (non-url, file:, git:, ssh:)
*** then unknown protocols are dispatched to external helper
*** so: rsync/local/git/ssh can't be reached from outside 'git fetch'
* hrm. basic potential strategies:
** allow the merge to happen, use the post-merge hook to examine the results,
   use the reflog to roll back if denied.
*** cons: uncommitted changes more likely to be lost, reflog pollution,
    working tree thrash
** get control with a remote-helper
*** pros: everything happens pre-merge, so no reflog pollution
*** then 1: fetch upstream with an alternative remote, examine, copy to real
    remote by passing through to "git upload-pack ." and pointing config's
    remote.fetch at refs/remotes/ALT
**** cons: using a remote.fetch like that doesn't update the right stuff
*** then 2: fetch with real remote, examine, throw exception on reject
**** cons
***** tracking branches are left with evil data,
****** but, they'll be updated by a subsequent fetch
***** subsequent manual merge would accept evil
***** tracking branches don't provide a handy "what was good" blessed history
      to prevent replay attacks (but the real local branch provides that)
*** then 3: fetch with real remote, examine, roll back and throw exception on
    reject
**** leaves tracking branches in a better state, and can be used for blessed
     history
*** but, how to get the real remote to work?
**** in the protocol handler, we can run a recursive 'git fetch' with the
     real URL on the same remote.. that will populate the tracking branches.
**** then examine+reject
**** but then how can we let the original fetch succeed and populate
     FETCH_HEAD correctly? need to let the protocol-handler do *something*
*** then 4: fetch with alternate remote, examine, then transform into a
    non-connect protocol helper. When the driver asks for what references the
    far side holds, respond with the refs that were just fetched (under their
    remote names, e.g. refs/heads/master). With luck, the driver will then
    stop talking, because those refs are already present in the alternate
    remote.
**** can use 'git ls-remote' to get the remote refs in exactly the same
     format that the protocol-helper "list" command wants
**** ah, but that introduces a TOUTTOC bug
**** so, need to fetch the canonical remote-ref list first, then populate the
     raw remote (with 'git fetch', hopefully with the same thing, but we
     don't rely on it), then examine refs from the canonical list, then
     return the canonical list
**** could we do the verification with just the list of refs? Only if we give
     up on replay defense (which needs to know the ancestry relationships
     between a previously-valid value and the new proposed value).
***** oh, actually, what we really need to know is that the proposed value is
      new (not in the known history). The upstream publisher will only sign
      things that are descendants, so any signed+new value must be a
      descendant of our most-recent blessed value. Then we *don't* need to
      pull everything first. Much easier.
***** also means the post-fetch hook isn't really post-fetch: it only gets to
      see the proposed new refs, and cannot examine the history or the actual
      tree/file contents.
***** if the hook wants to look deeper, it can manually fetch each proposed
      ref
**** ok, so ls-remote gets a full list of refs. Which ones will we care
     about?
***** style 1: validate during 'git fetch', bad references won't even get
      added to the remote-tracking branch. This enables arbitrary git
      pull/fetch/merge operations. This can use protocol helpers to get
      control in the middle of the fetch. The virtual hook we're providing
      would be called "pre-fetch" or "post-fetch with rejection abilities",
      or maybe "mid-fetch" if it only gets to see the refs and not the actual
      contents.
****** If we do it this way, we really need to roll back the tracking
       branches upon error, otherwise discrete 'git fetch; git merge'
       commands won't protect the user ('git fetch && git merge' would).
****** ah, but if we throw at the midpoint, the fetch will fail, and the
       tracking branches won't ever be updated.
***** style 2: validate during 'git merge', remote-tracking branches will
      have bad refs but they don't be merged into local branches. This only
      protects users during the merge step. We have fewer hooks to implement
      this (post-merge, which would need the reflog-based
      rollback-on-rejection scheme). The virtual hook could be called
      "pre-merge" since it effectively gets to reject merges.
***** Maybe the git-assure config should associated a key with each refname
      ("key-abc123.. refs/heads/master"), rather than associated keys with
      local tracking branch names.
** go with mid-fetch:
*** get control with a protocol helper
*** the helper does a ls-remote, gets the ref list, passes to the hook for
    judgement. If the hook needs more information than just the reference
    value, it must fetch individual refs (and must not modify the real
    tracking branch). The hook can look in the git-assure config to find the
    key+remoterefname mapping, so it knows which to examine and which to
    ignore
**** [#A] option 1: hook is given the reflist text on stdin, exits with 0 to
     accept, !=0 to reject
**** option 2: hook is given raw remote name in argv, must do its own
     ls-remote, must return reflist text on stdout
**** option 3: hook gets raw remote name in argv, does its own ls-remote,
     returns validated subset of reflist on stdout. helper rejects unless
     every ref that the hook returned matches the reflist it sees.
*** the helper then needs to pull the right refs into a raw remote, so the
    objects will be local, so the helper doesn't need to implement the
    'fetch' command. It can just spawn 'git fetch --no-tags remote-raw'. This
    might fetch evil references, but they won't go beyond the raw remote. And
    the raw remote can be deleted immediately (they won't be gc'ed right
    away).
*** then the helper returns the original ls-remote list to the driver, which
    should then terminate. If the raw fetch didn't supply enough refs, the
    driver will ask for 'fetch', which will return an error.
** to avoid $PATH changes or installation step, need different kind of proxy
*** intercept the "git" protocol instead of the remote-helper protocol
*** protocol is more complex, but should have the same basic functions
*** url = ext::./.git/TOOL REMOTENAME REALURL
**** quick testing suggests it's executed from the repo basedir, which means
     the TOOL path we embed can be relative, allowing the repo to be moved
     around without breakage
*** git/Documentation/technical/pack-protocol.txt "Reference Discovery" says
    that the server should respond with "pkt-line stream" of references: each
    line starts with a 4-char hex (004a) length (including the length
    length), then the hex revid, then a space, then the refname, then a
    newline (included in the length, but ignored after unpacking). The first
    line should also have \0 and a list of space-separated capabilities (all
    included in the length), but I think my proxy can skip that (older
    clients wouldn't have it). The last line should be just "0000".
*** so my proxy can start by running git-ls-remote and run the mid-fetch
    hook, then report the ref list in the expected format. At that point the
    client ought to disconnect, with nothing to do.
* setup needed:
** given a remote name:
   - set remote.NAME.pushurl = remote.NAME.url
   - set remote.NAME.url = ext::.git/TOOL REMOTE URL
   - set remote.NAME.assure = KEY for BRANCH
     - multiple lines for multiple branches
   - add .git/TOOL, chmod+X
** for publishers, add:
   - add branch.NAME.assure-key with the signing+verifying keys
   - add remote.NAME.push refspec that pushes notes too. Default is ":",
     which means "matching branches". Should have two lines, one with ":" and
     one with "refs/notes/commits:refs/notes/commits"
* tools to build / things to fix
** DONE Figure out how to avoid $PATH changes. Using "assure::" searches for
   git-remote-assure. I wish git-remote-ext would do it, but no, that's only
   for the "connect" protocol.
*** maybe there's a .git/config setting to modify $PATH during git commands?
    I see entries for difftool and mergetool.TOOL.path
*** transport-helper.c:get_helper() (line 128) is the relevant bit
*** maybe hack it with gitcredentials? you can configure a path to the
    credential helper. But it looks like only C code can request access to
    the credentials API.
*** if I run the "smart" git protocol, I could use core.gitProxy, or
    git-remote-ext
*** look for how libexec/git-core is baked into the search path.
    run-command.c is probably relevant.
** rely on $GIT_DIR instead of $cwd
** build a python-ed25519 -API -compliant form of the pure-python
   dholth-ed25519ll code, in a single file
** the pure-python form takes about 20ms to verify a signature.. consider
   excluding unchanged branches from the signature check, to save time, when
   there are dozens or hundreds of branches.
** DONE build tools to assemble the right scripts from source pieces
** consider abandoning the mid-fetch hook and doing everything inside
   git-remote-assure, probably simpler to construct a single file than two
   separate ones with overlapping contents
** DONE build the tools in reverse order:
*** subscriber either clones and then runs ./setup-assure, or pre-installs
    git-assure and runs "git-assure clone KEY URL"
**** setup-assure contains an embedded key (one per branch)
**** Running setup-assure installs .git/TOOL (call it "assure-tool"), then
     runs "TOOL subscribe BRANCH KEY"
**** "TOOL subscribe" modifies .git/config to run "TOOL fetch" on
     fetch, and to add the verifying key for that branch
*** publisher installs git-assure, runs "git-assure setup-publish"
**** that first installs .git/TOOL
**** that then runs "TOOL setup-publish --create-keypair" for the
     publish-specific parts: create keypair, store in .git/config, add
     post-commit hook (to run "TOOL sign")
**** then it creates and git-adds setup-assure, advises to commit and push
     - by reading out the key in .git/config created by setup-publish
     - contents of setup-publish include a copy of .git/TOOL
**** ?then it runs "TOOL subscribe" to perform setup-assure steps
     - seems useful for shared-publisher arrangements, but requires doing
       subscriber setup on each branch
**** (this way, anyone with a checkout can become a publisher by just
     learning the signing key: they run ".git/TOOL setup-publish" and fill in
     the key)
*** I build+publish git-assure, from smaller pieces
** 
** setup-publish --create-keypair should set branch.NAME.assure-key in
   addition to .assure-sign-key : once you start publishing sigs, you should
   expect sigs back. That will also trigger the setup-assure creation to
   include those keys
** DONE maybe put the list of "branches which are supposed to be signed" in a
   separate file? What happens when you add one later.. should we re-generate
   setup-assure?
** DONE merge setup_assure_header_b64 and _footer_b64. The keyconfig doesn't
   depend upon the header, so just build keyconfig+setup_assure_b64. The
   header has only a welcome comment, but since the keyconfig is pretty
   short, you'd still see the welcome message even if it weren't at the
   tippy-top of the file.
** DONE merge git-assure and assure-tool? just invoke it in different ways?
*** "git-assure setup-publish" needs a copy of git-assure. use argv[0], read
    its contents, base64-encode, include inside the generated setup-assure
*** setup-client is included in assure-tool, but unused (only called from
    setup-assure)
** DONE change substitution code in setup.py to wrap each interpolated block
   with "== BEGIN/END $name ==", then remove same from assure-tool-template
** DONE move .git/config-changing code out of setup-assure and into
   "assure-tool subscribe". maybe. the fact that this part is driven by the
   embedded keyconfig suggests otherwise.
** DONE fewer substitutions. "sign" and "report" are only used in assure-tool
** DONE in post-commit-hook.template, run "git-assure sign" instead of
   "assure-tool post-commit", since internally it will run sign() anyways.
   Likewise the client-side url configuration calls "assure-tool fetch",
   which internally runs assure_proxy(), and should be renamed to make things
   easier to follow.
*** hm, "assure-tool post-commit" is probably the best name: hooks are a very
    specific environment, whereas "sign" as a command name sounds like it
    could be run by a human. So stick with "post-commit" and change the
    internals to match.
** DONE general approach: build an end-to-end test, then start breaking
   things
** change signature code: if pynacl or python-ed25519 is installed globally,
   use it (faster), but always be able to fall back to the included
   pure-python version
** DONE src/assure-proxy.py uses os.unlink(.git/FETCH_HEAD), maybe should use
   "git update-ref --delete FETCH_HEAD" instead
** DONE new name: "git-lockup"?
** DONE setup-publish: git add the "setup-assure" and "assure.config" files
** DONE setup.py build: create git-assure in a mktmp file, not build/temp,
   it's kind of in the way for tab-completion of build/[TAB]
** make setup-assure locate the assure.config file (next to argv[0]) and pass
   it as an argument into "git-assure setup-client". Default usage is to put
   setup-assure in the top of the project tree, but make it possible to go
   into misc/ or something. Consider moving assure.config to .assure.cfg or
   .assure.yaml or something, in which case setup-assure should look for it
   in the top of the git tree.
** implement "subscribe". maybe just rename setup-client and make sure its
   idempotent. maybe rename setup-publish to just "publish"
* current design (08-Oct-2013)
** first publisher must have a copy of git-assure
** they run "git-assure setup-publish" in their project tree
*** that adds .git/assure-tool
*** calls .git/assure-tool setup-publish --create-keypair master
**** that creates a keypair, updates .git/config, adds post-commit hook
*** then creates ./setup-assure for clients, configured with a verfkey for
    every branch that has a "branch.NAME.assure-key" in .git/config, and
    includes a copy of assure-tool
** subscribers run ./setup-assure
*** ./setup-assure has the keyconfig from the publisher, plus a copy of
    assure-tool
*** adds .git/assure-tool
*** for each configured branch, calls setup_client() to modify .git/config
**** set remote.NAME.url to ext::.git/assure-tool fetch REMOTE RAWURL
**** set remote.NAME.pushurl (to either RAWURL or a pre-existing pushurl)
**** add branch.NAME.assure-key if not already set
* new design:
** first publisher has copy of git-lockup, runs "git lockup setup-publish"
*** that has a default behavior of --create-keypair=master
*** it copies git-lockup into .git/git-lockup verbatim
*** then creates a keypair, updates .git/config, adds post-commit hook
*** then creates ./setup-lockup for clients, which include a copy of
    git-lockup
*** then creates lockup.config with the branch info
** post-commit hook runs ".git/git-lockup post-commit", which signs
** subscribers run ./setup-lockup
*** that dumps .git/git-lockup
*** then runs .git/git-lockup setup-client
**** which reads lockup.config, modifies .git/config:
***** set remote.NAME.url to "ext::.git/git-lockup fetch-proxy REMOTE RAWURL"
***** set remote.NAME.pushurl (to either RAWURL or a pre-existing pushurl)
***** add branch.NAME.lockup-key if not already set

* bugs
** DONE setup-lockup needs a shbang
** publish config is no longer pushing the normal branches (it pushes notes,
   but "push = :" is no longer enough to trigger the defaults)
*** probably a newer git thing
*** manually doing a "git push origin master" fixes it, once
** 'git pull' couldn't find notes
*** then 'git update-ref delete' failed
